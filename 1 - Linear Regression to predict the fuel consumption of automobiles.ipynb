{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Machine Learning with PySpark Combo</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Linear Regression</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Linear Regression to predict the fuel consumption of automobiles.\n",
    "\n",
    "The **consumption** variable in dataset1.csv will be the target variable (dependent) and the other variables will be candidate features (predictive or independent variables).\n",
    "\n",
    "This is, therefore, a Multiple Linear Regression problem (when we have more than 1 predictor or independent variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import findspark and initialize\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Spark Context\n",
    "sc = SparkContext(appName = \"ML-Combo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Spark Session\n",
    "spSession = SparkSession.builder.master(\"local\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data and generating an RDD\n",
    "data = sc.textFile(\"data/dataset1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data/dataset1.csv MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Caching the RDD. This process optimizes the performance\n",
    "data.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "399"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of records\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['consumption,number_cylinders,capacity,horsepower,weight,acceleration,year,name',\n",
       " '30,4,79,70,2074,19.5,71,peugeot 304',\n",
       " '30,4,88,76,2065,14.5,71,fiat 124b',\n",
       " '31,4,71,65,1773,19,71,toyota corolla 1200',\n",
       " '35,4,72,69,1613,18,71,datsun 1200']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing the first lines of an RDD\n",
    "data.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "398"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing the first line of the file (header)\n",
    "data2 = data.filter(lambda x: \"horsepower\" not in x)\n",
    "data2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['30,4,79,70,2074,19.5,71,peugeot 304',\n",
       " '30,4,88,76,2065,14.5,71,fiat 124b',\n",
       " '31,4,71,65,1773,19,71,toyota corolla 1200',\n",
       " '35,4,72,69,1613,18,71,datsun 1200',\n",
       " '27,4,97,60,1834,19,71,volkswagen model 111']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the first lines\n",
    "data2.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Data Cleanup\n",
    "\n",
    "Let's check for missing values. RDDs are great for processing but bad for exploration, so we'll convert the RDD to Spark DataFrame and then to Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert RDD to Spark DataFrame\n",
    "df_spark = data2.map(lambda x: str(x)).map(lambda w: w.split(',')).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Spark DataFrame to Pandas DataFrame\n",
    "df_pandas = df_spark.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_1</th>\n",
       "      <th>_2</th>\n",
       "      <th>_3</th>\n",
       "      <th>_4</th>\n",
       "      <th>_5</th>\n",
       "      <th>_6</th>\n",
       "      <th>_7</th>\n",
       "      <th>_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>79</td>\n",
       "      <td>70</td>\n",
       "      <td>2074</td>\n",
       "      <td>19.5</td>\n",
       "      <td>71</td>\n",
       "      <td>peugeot 304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>88</td>\n",
       "      <td>76</td>\n",
       "      <td>2065</td>\n",
       "      <td>14.5</td>\n",
       "      <td>71</td>\n",
       "      <td>fiat 124b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>71</td>\n",
       "      <td>65</td>\n",
       "      <td>1773</td>\n",
       "      <td>19</td>\n",
       "      <td>71</td>\n",
       "      <td>toyota corolla 1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>72</td>\n",
       "      <td>69</td>\n",
       "      <td>1613</td>\n",
       "      <td>18</td>\n",
       "      <td>71</td>\n",
       "      <td>datsun 1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>97</td>\n",
       "      <td>60</td>\n",
       "      <td>1834</td>\n",
       "      <td>19</td>\n",
       "      <td>71</td>\n",
       "      <td>volkswagen model 111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _1 _2  _3  _4    _5    _6  _7                    _8\n",
       "0  30  4  79  70  2074  19.5  71           peugeot 304\n",
       "1  30  4  88  76  2065  14.5  71             fiat 124b\n",
       "2  31  4  71  65  1773    19  71   toyota corolla 1200\n",
       "3  35  4  72  69  1613    18  71           datsun 1200\n",
       "4  27  4  97  60  1834    19  71  volkswagen model 111"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pandas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Does it have null values?\n",
    "df_pandas.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no null value, but is there a missing value (lack of information)? Let's check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there is any line with special character \"?\"\n",
    "total = np.sum(df_pandas.apply(lambda x: x.str.contains('\\?')).values)\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 48, 126, 330, 336, 354, 374], dtype=int64),\n",
       " array([3, 3, 3, 3, 3, 3], dtype=int64))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vejamos quais linhas e colunas têm o caracter especial\n",
    "np.where(df_pandas.apply(lambda x: x.str.contains('\\?')).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_1                    40.9\n",
       "_2                       4\n",
       "_3                      85\n",
       "_4                       ?\n",
       "_5                    1835\n",
       "_6                    17.3\n",
       "_7                      80\n",
       "_8    renault lecar deluxe\n",
       "Name: 330, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing a line\n",
    "df_pandas.iloc[330]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a default value for average HP (which will be used to fill in the missing values)\n",
    "avgHP = sc.broadcast(75.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clear data\n",
    "def cleardata(inputStr) :\n",
    "    \n",
    "    # global variable\n",
    "    global avgHP\n",
    "    \n",
    "    # Attribute list\n",
    "    attList = inputStr.split(\",\")\n",
    "    \n",
    "    # Replace the ? by a value in index column 3\n",
    "    hpValue = attList[3]\n",
    "    if hpValue == \"?\":\n",
    "        hpValue = avgHP.value\n",
    "       \n",
    "    # Create a row using the Row function, clearing and converting the data from string to float\n",
    "    rows = Row(consumption = float(attList[0]), \n",
    "                 number_cylinders = float(attList[1]), \n",
    "                 capacity = float(attList[2]), \n",
    "                 horsepower = float(hpValue), \n",
    "                 weight = float(attList[4]), \n",
    "                 acceleration = float(attList[5]), \n",
    "                 year = float(attList[6]), \n",
    "                 name = attList[7]) \n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(consumption=30.0, number_cylinders=4.0, capacity=79.0, horsepower=70.0, weight=2074.0, acceleration=19.5, year=71.0, name='peugeot 304'),\n",
       " Row(consumption=30.0, number_cylinders=4.0, capacity=88.0, horsepower=76.0, weight=2065.0, acceleration=14.5, year=71.0, name='fiat 124b'),\n",
       " Row(consumption=31.0, number_cylinders=4.0, capacity=71.0, horsepower=65.0, weight=1773.0, acceleration=19.0, year=71.0, name='toyota corolla 1200'),\n",
       " Row(consumption=35.0, number_cylinders=4.0, capacity=72.0, horsepower=69.0, weight=1613.0, acceleration=18.0, year=71.0, name='datsun 1200'),\n",
       " Row(consumption=27.0, number_cylinders=4.0, capacity=97.0, horsepower=60.0, weight=1834.0, acceleration=19.0, year=71.0, name='volkswagen model 111')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the function in RDD\n",
    "data3 = data2.map(cleardata)\n",
    "data3.cache()\n",
    "data3.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dataframe\n",
    "df_cars = spSession.createDataFrame(data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-----------------+\n",
      "|summary|      consumption| number_cylinders|\n",
      "+-------+-----------------+-----------------+\n",
      "|  count|              398|              398|\n",
      "|   mean|23.51457286432161|5.454773869346734|\n",
      "| stddev|7.815984312565782|1.701004244533212|\n",
      "|    min|              9.0|              3.0|\n",
      "|    max|             46.6|              8.0|\n",
      "+-------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Two-variable descriptive statistics (as an example)\n",
    "df_cars.select(\"consumption\", \"number_cylinders\").describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation of the Target Variable with: consumption 1.0\n",
      "Correlation of the Target Variable with: number_cylinders -0.7753962854205546\n",
      "Correlation of the Target Variable with: capacity -0.8042028248058979\n",
      "Correlation of the Target Variable with: horsepower -0.7747041523498721\n",
      "Correlation of the Target Variable with: weight -0.8317409332443347\n",
      "Correlation of the Target Variable with: acceleration 0.42028891210164976\n",
      "Correlation of the Target Variable with: year 0.5792671330833099\n"
     ]
    }
   ],
   "source": [
    "# Finding the correlation between the target variable and the predictor variables (except the name)\n",
    "for i in df_cars.columns:\n",
    "    if not(isinstance(df_cars.select(i).take(1)[0][0], str)):\n",
    "        print(\"Correlation of the Target Variable with:\", i, df_cars.stat.corr('consumption', i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to a LabeledPoint(target, Vector[features])\n",
    "# Remove columns that are not relevant or have low correlation\n",
    "def transformVar(row) :\n",
    "    obj = (row[\"consumption\"], Vectors.dense([row[\"weight\"], row[\"capacity\"], row[\"number_cylinders\"]]))\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the RDD and create another RDD\n",
    "data4 = data3.map(transformVar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(30.0, DenseVector([2074.0, 79.0, 4.0])),\n",
       " (30.0, DenseVector([2065.0, 88.0, 4.0])),\n",
       " (31.0, DenseVector([1773.0, 71.0, 4.0])),\n",
       " (35.0, DenseVector([1613.0, 72.0, 4.0])),\n",
       " (27.0, DenseVector([1834.0, 97.0, 4.0]))]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View\n",
    "data4.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert RDD to Spark DataFrame\n",
    "df_cars = spSession.createDataFrame(data4, [\"label\", \"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|label|          features|\n",
      "+-----+------------------+\n",
      "| 30.0| [2074.0,79.0,4.0]|\n",
      "| 30.0| [2065.0,88.0,4.0]|\n",
      "| 31.0| [1773.0,71.0,4.0]|\n",
      "| 35.0| [1613.0,72.0,4.0]|\n",
      "| 27.0| [1834.0,97.0,4.0]|\n",
      "| 26.0| [1955.0,91.0,4.0]|\n",
      "| 24.0|[2278.0,113.0,4.0]|\n",
      "| 25.0| [2126.0,97.5,4.0]|\n",
      "| 23.0| [2254.0,97.0,4.0]|\n",
      "| 20.0|[2408.0,140.0,4.0]|\n",
      "+-----+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View label (y) and attributes (x)\n",
    "df_cars.select(\"label\",\"features\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into Training and Test data with 70/30 split\n",
    "(training_data, test_data) = df_cars.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "286"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the object\n",
    "linearReg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the object with data and create the model\n",
    "model = linearReg.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegressionModel: uid=LinearRegression_d9ff98be1278, numFeatures=3\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-0.005913037974367063,-0.006669421078096151,-0.6419921295574764]\n",
      "Intercept: 45.75464773056361\n"
     ]
    }
   ],
   "source": [
    "# Printing the coefficients (what the model has learned)\n",
    "print(\"Coefficients: \" + str(model.coefficients))\n",
    "print(\"Intercept: \" + str(model.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions with test data\n",
    "predictions = model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|          features|        prediction|\n",
      "+------------------+------------------+\n",
      "|[4615.0,360.0,8.0]|10.929048854285192|\n",
      "|[4997.0,400.0,8.0]|  8.40349150495313|\n",
      "|[4499.0,350.0,8.0]|11.681655470092728|\n",
      "|[4906.0,400.0,8.0]| 8.941577960620528|\n",
      "|[3821.0,360.0,8.0]|15.624001005932637|\n",
      "|[4100.0,350.0,8.0]| 14.04095762186519|\n",
      "|[4464.0,400.0,8.0]|11.555140745290771|\n",
      "|[4654.0,360.0,8.0]|10.698440373284875|\n",
      "|[4735.0,440.0,8.0]| 9.685930611113449|\n",
      "|[4746.0,400.0,8.0]| 9.887664036519261|\n",
      "|[5140.0,400.0,8.0]|7.5579270746186396|\n",
      "|[3672.0,304.0,8.0]|16.878531244486716|\n",
      "|[4042.0,302.0,8.0]|14.704046036127092|\n",
      "|[4129.0,351.0,8.0]| 13.86281009953045|\n",
      "|[4154.0,351.0,8.0]|13.714984150171269|\n",
      "|[4257.0,304.0,8.0]|13.419404029481989|\n",
      "|[4385.0,400.0,8.0]|12.022270745265764|\n",
      "|[4457.0,318.0,8.0]|12.143424539515223|\n",
      "|[3693.0,350.0,8.0]|16.447564077432585|\n",
      "|[3761.0,400.0,8.0]|15.712006441270816|\n",
      "+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View forecasts\n",
    "predictions.select(\"features\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficient of determination R2\n",
    "evaluator = RegressionEvaluator(predictionCol = \"prediction\", labelCol = \"label\", metricName = \"r2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6858033570914506"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Result\n",
    "evaluator.evaluate(predictions) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disclaimer: \n",
    "A good part of this project was largely done in the Data Science Academy, Big Data Real-Time Analytics with Python and Spark course (part of the Data Scientist training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
